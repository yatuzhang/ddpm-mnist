{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DDPM Training on Google Colab with Real-time Visualization\n",
        "\n",
        "This notebook trains a DDPM model on MNIST using GPU acceleration with live progress tracking, loss graphs, and sample visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install denoising_diffusion_pytorch torch torchvision matplotlib tqdm seaborn plotly\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output, display\n",
        "import time\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"⚠️ No GPU detected! Training will be slow on CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone your repository\n",
        "!git clone https://github.com/yatuzhang/ddpm-mnist.git\n",
        "%cd ddpm-mnist\n",
        "\n",
        "# List files to verify\n",
        "!ls -la\n",
        "\n",
        "# Create directories for outputs\n",
        "import os\n",
        "os.makedirs('colab_outputs', exist_ok=True)\n",
        "os.makedirs('colab_outputs/samples', exist_ok=True)\n",
        "os.makedirs('colab_outputs/checkpoints', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enhanced training script with real-time visualization\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from denoising_diffusion_pytorch import Unet, GaussianDiffusion\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from IPython.display import clear_output, display\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "def get_data_loaders(batch_size=128, num_workers=2):\n",
        "    \"\"\"Get MNIST data loaders.\"\"\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "    \n",
        "    train_dataset = datasets.MNIST(\n",
        "        root='./data', train=True, download=True, transform=transform\n",
        "    )\n",
        "    test_dataset = datasets.MNIST(\n",
        "        root='./data', train=False, download=True, transform=transform\n",
        "    )\n",
        "    \n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
        "    )\n",
        "    \n",
        "    return train_loader, test_loader\n",
        "\n",
        "def create_model(device):\n",
        "    \"\"\"Create DDPM model.\"\"\"\n",
        "    model = Unet(\n",
        "        dim=64,\n",
        "        channels=1,\n",
        "        dim_mults=(1, 2, 4),\n",
        "        flash_attn=True\n",
        "    )\n",
        "    \n",
        "    diffusion = GaussianDiffusion(\n",
        "        model,\n",
        "        image_size=28,\n",
        "        timesteps=1000,\n",
        "        sampling_timesteps=250,\n",
        "        objective='pred_v'\n",
        "    ).to(device)\n",
        "    \n",
        "    return diffusion\n",
        "\n",
        "def save_samples_grid(samples, title=\"Generated Samples\", nrow=4, ncol=4):\n",
        "    \"\"\"Save samples in a grid format.\"\"\"\n",
        "    samples = (samples + 1) / 2\n",
        "    samples = torch.clamp(samples, 0, 1)\n",
        "    \n",
        "    fig, axes = plt.subplots(nrow, ncol, figsize=(ncol*2, nrow*2))\n",
        "    if nrow == 1 and ncol == 1:\n",
        "        axes = [axes]\n",
        "    elif nrow == 1 or ncol == 1:\n",
        "        axes = axes.flatten()\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "    \n",
        "    for i in range(min(nrow * ncol, len(samples))):\n",
        "        axes[i].imshow(samples[i].squeeze().cpu().numpy(), cmap='gray')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    for i in range(nrow * ncol, len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "    \n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def visualize_denoising_process(diffusion, original_image, device, save_path=None):\n",
        "    \"\"\"Visualize the denoising process step by step.\"\"\"\n",
        "    diffusion.eval()\n",
        "    \n",
        "    # Get a random timestep\n",
        "    t = torch.randint(0, diffusion.num_timesteps, (1,), device=device)\n",
        "    \n",
        "    # Add noise to original image\n",
        "    noise = torch.randn_like(original_image)\n",
        "    noisy_image = diffusion.q_sample(original_image, t, noise)\n",
        "    \n",
        "    # Denoise step by step\n",
        "    denoised_images = [noisy_image]\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # Use DDIM sampling for visualization\n",
        "        x = noisy_image\n",
        "        for i in range(0, diffusion.num_timesteps, 50):  # Every 50 steps\n",
        "            t_batch = torch.full((1,), i, device=device, dtype=torch.long)\n",
        "            predicted_noise = diffusion.model(x, t_batch)\n",
        "            x = diffusion.p_sample(x, i)  # p_sample expects integer timestep\n",
        "            denoised_images.append(x)\n",
        "    \n",
        "    # Create comparison plot\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    \n",
        "    images_to_show = [\n",
        "        original_image, noisy_image, \n",
        "        denoised_images[2], denoised_images[4],\n",
        "        denoised_images[6], denoised_images[8],\n",
        "        denoised_images[10], denoised_images[-1]\n",
        "    ]\n",
        "    \n",
        "    titles = ['Original', 'Noisy', 'Step 100', 'Step 200', \n",
        "              'Step 300', 'Step 400', 'Step 500', 'Final']\n",
        "    \n",
        "    for i, (img, title) in enumerate(zip(images_to_show, titles)):\n",
        "        row, col = i // 4, i % 4\n",
        "        axes[row, col].imshow(img.squeeze().cpu().numpy(), cmap='gray')\n",
        "        axes[row, col].set_title(title)\n",
        "        axes[row, col].axis('off')\n",
        "    \n",
        "    plt.suptitle('Denoising Process Visualization', fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    \n",
        "    return fig\n",
        "\n",
        "def train_with_visualization(epochs=50, batch_size=128):\n",
        "    \"\"\"Train with real-time visualization.\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "    \n",
        "    # Get data loaders\n",
        "    train_loader, test_loader = get_data_loaders(batch_size)\n",
        "    \n",
        "    # Create model\n",
        "    diffusion = create_model(device)\n",
        "    print(f\"Model created with {sum(p.numel() for p in diffusion.parameters())} parameters\")\n",
        "    \n",
        "    # Create optimizer\n",
        "    optimizer = optim.AdamW(diffusion.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "    \n",
        "    # Training history\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    \n",
        "    # Get a sample image for denoising visualization\n",
        "    sample_batch = next(iter(test_loader))[0][:1].to(device)\n",
        "    \n",
        "    print(\"Starting training with real-time visualization...\")\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        diffusion.train()\n",
        "        total_loss = 0\n",
        "        \n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "        for batch_idx, (data, _) in enumerate(pbar):\n",
        "            data = data.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = diffusion(data)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
        "        \n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        \n",
        "        # Testing\n",
        "        diffusion.eval()\n",
        "        test_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for data, _ in test_loader:\n",
        "                data = data.to(device)\n",
        "                loss = diffusion(data)\n",
        "                test_loss += loss.item()\n",
        "        \n",
        "        avg_test_loss = test_loss / len(test_loader)\n",
        "        test_losses.append(avg_test_loss)\n",
        "        \n",
        "        # Generate samples\n",
        "        with torch.no_grad():\n",
        "            samples = diffusion.sample(batch_size=16)\n",
        "        \n",
        "        # Clear output and show progress\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        # Create comprehensive visualization\n",
        "        fig = plt.figure(figsize=(20, 12))\n",
        "        \n",
        "        # Loss plot\n",
        "        plt.subplot(2, 4, 1)\n",
        "        plt.plot(train_losses, label='Train Loss', color='blue')\n",
        "        plt.plot(test_losses, label='Test Loss', color='red')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Progress')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        \n",
        "        # Generated samples\n",
        "        plt.subplot(2, 4, (2, 4))\n",
        "        samples_grid = save_samples_grid(samples, f'Generated Samples - Epoch {epoch}')\n",
        "        plt.show()\n",
        "        \n",
        "        # Denoising process\n",
        "        plt.subplot(2, 4, (5, 8))\n",
        "        denoising_fig = visualize_denoising_process(diffusion, sample_batch, device)\n",
        "        plt.show()\n",
        "        \n",
        "        # Save samples\n",
        "        samples_grid.savefig(f'colab_outputs/samples/epoch_{epoch:03d}_samples.png', \n",
        "                           dpi=150, bbox_inches='tight')\n",
        "        denoising_fig.savefig(f'colab_outputs/samples/epoch_{epoch:03d}_denoising.png', \n",
        "                            dpi=150, bbox_inches='tight')\n",
        "        \n",
        "        # Save checkpoint\n",
        "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': diffusion.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_losses': train_losses,\n",
        "                'test_losses': test_losses,\n",
        "            }, f'colab_outputs/checkpoints/checkpoint_epoch_{epoch:03d}.pth')\n",
        "        \n",
        "        print(f'Epoch {epoch:3d}: Train Loss = {avg_train_loss:.4f}, Test Loss = {avg_test_loss:.4f}')\n",
        "        \n",
        "        # Close figures to free memory\n",
        "        plt.close('all')\n",
        "    \n",
        "    print(\"Training completed!\")\n",
        "    return diffusion, train_losses, test_losses\n",
        "\n",
        "# Start training\n",
        "diffusion, train_losses, test_losses = train_with_visualization(epochs=50, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate final samples and create summary\n",
        "print(\"Generating final samples...\")\n",
        "\n",
        "# Generate more samples for final evaluation\n",
        "with torch.no_grad():\n",
        "    final_samples = diffusion.sample(batch_size=64)\n",
        "\n",
        "# Create a large grid of final samples\n",
        "fig, axes = plt.subplots(8, 8, figsize=(16, 16))\n",
        "for i in range(64):\n",
        "    row, col = i // 8, i % 8\n",
        "    axes[row, col].imshow(final_samples[i].squeeze().cpu().numpy(), cmap='gray')\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.suptitle('Final Generated Samples (64 images)', fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('colab_outputs/final_samples_64.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Create training summary\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss curves\n",
        "ax1.plot(train_losses, label='Train Loss', color='blue', linewidth=2)\n",
        "ax1.plot(test_losses, label='Test Loss', color='red', linewidth=2)\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Training Progress')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Loss improvement\n",
        "ax2.plot(np.diff(train_losses), label='Train Loss Change', color='blue', alpha=0.7)\n",
        "ax2.plot(np.diff(test_losses), label='Test Loss Change', color='red', alpha=0.7)\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Loss Change')\n",
        "ax2.set_title('Loss Improvement Over Time')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('colab_outputs/training_summary.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Final training loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Final test loss: {test_losses[-1]:.4f}\")\n",
        "print(f\"Total improvement: {train_losses[0] - train_losses[-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download results\n",
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create zip file with all results\n",
        "with zipfile.ZipFile('ddpm_training_results.zip', 'w') as zipf:\n",
        "    # Add all output files\n",
        "    for root, dirs, files in os.walk('colab_outputs'):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            zipf.write(file_path, file_path)\n",
        "    \n",
        "    # Add final samples\n",
        "    if os.path.exists('colab_outputs/final_samples_64.png'):\n",
        "        zipf.write('colab_outputs/final_samples_64.png')\n",
        "    if os.path.exists('colab_outputs/training_summary.png'):\n",
        "        zipf.write('colab_outputs/training_summary.png')\n",
        "\n",
        "print(\"Files to download:\")\n",
        "for root, dirs, files in os.walk('colab_outputs'):\n",
        "    for file in files:\n",
        "        print(f\"  - {os.path.join(root, file)}\")\n",
        "\n",
        "# Download the zip file\n",
        "files.download('ddpm_training_results.zip')\n",
        "\n",
        "print(\"\\n🎉 Training completed successfully!\")\n",
        "print(\"📁 All results have been saved and downloaded.\")\n",
        "print(\"📊 Check the visualizations above to see your model's progress!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
